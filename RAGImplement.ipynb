{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph langchain-ollama langchain-huggingface beautifulsoup4 sentence-transformers langchain langchain-openai ipywidgets jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restart the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [Ollama](https://ollama.com/) and run it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith(Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "LANGCHAIN_TRACING_V2='true'\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_API_KEY=\"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\"# Place your API Key\n",
    "LANGCHAIN_PROJECT=\"RAG_SELAB\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = LANGCHAIN_TRACING_V2\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = LANGCHAIN_ENDPOINT\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY \n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Create LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "# model = \"llama3.2\"\n",
    "model = \"mistral\"\n",
    "llm = OllamaLLM(model=model, base_url=\"http://localhost:11434\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = \"我在測試專案\"\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"你好，請問你能幫我什麼？\"}\n",
    "# ]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Create Embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English:  \n",
    "sentence-transformers/all-MiniLM-L6-v2  \n",
    "intfloat/multilingual-e5-small  \n",
    "\n",
    "\n",
    "chinese model([https://ihower.tw/blog/archives/12167](https://ihower.tw/blog/archives/12167)):  \n",
    "BAAI/bge-m3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Load Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'docs/SElab_Industry_Academia_Collaboration.pdf', 'page': 0}, page_content='實驗室簡介\\n簡短介紹\\n我們是軟體⼯程實驗室，主要在做軟體測試相關的研究，包含  Android 爬蟲測試、網⾴\\n表單爬蟲測試、對 RESTful API 做模糊測試以及微服務等\\n另外也還有和振興醫院合作的醫療影像相關研究，分別是⼼臟彩⾊超⾳波和主動脈，是\\n和尤信程教授共同指導的。\\n⽬前實驗室多數研究都在結合  LLM 來進⾏改良\\n各項研究說明\\nAndroid 爬蟲測試 ( 建宏老師 )\\n⽬的：\\n現今有越來越多  Android 程式被開發出來，如何確保程式品質，測試是不可或缺的⼀環\\nACE\\n我們先前開發出了⼀款名為  ACE (Android CrawlEr) 的  Android GUI ⾃動化測試⼯具\\nACE 主要透過爬⾏  GUI (Graphical User Interface) 畫⾯⾃動探索應⽤程式\\n⽀援不同的爬⾏策略，包含強化學習和好奇⼼驅動兩種演算法\\nAAD\\nAAD (Android Anomaly Detector) 則是延伸  ACE ，使⽤從 ACE 爬⾏產⽣的路徑進⾏操作注\\n入\\n負責偵測  APP 發⽣  Anomaly （異常）的情況\\nAnomaly 是指程式⾏為和預期 (Expect) 不同\\n例如：我們預期程式在來回翻轉畫⾯前後⾏為 ( 畫⾯ ) 相同\\n但有些程式因為開發時的缺失，造成翻轉畫⾯後對話框消失\\n使⽤像是來回翻轉畫⾯或是離開  APP 再進去等⽅式來偵測\\nATAS\\nATAS (Android Test Automation Service) 是⼀個測試暨服務平台\\n整合  ACE 、 AAD 與  Android Emulator 並進⾏容器化\\n讓測試⼯具在無需實體機器的情況下，即可進⾏  APP 測試\\n2025/1/10 下午 4:20 實驗室簡介  - HackMD\\nhttps://hackmd.io/@fNmP5OVcSRmw0KivmULuHg/B1-cFT6gkl 3/10'), Document(metadata={'source': 'docs/SElab_Industry_Academia_Collaboration.pdf', 'page': 1}, page_content='現況 :\\n⽬前碩⼆在做的⽅向包含利⽤  LLM 決定探索的路徑或是想要觸發的事件，⽬的在提⾼程式覆蓋率\\n(ACE ⽅⾯ ) ，以及注入操作中的輸入文字的產⽣ (AAD ⽅⾯ )\\n網⾴代理⼈爬蟲 ( 建宏老師  with 尤老師 )\\n動機與⽬的：\\n現今許多服務都以網⾴應⽤程式的形式推出，讓網⾴測試顯得更加重要。⼿動測試不僅\\n耗時，且對測試⼈員的  Domain Knowledge 要求很⾼。⾃動化測試通過使⽤網⾴爬蟲\\n⾃動進⾏爬⾏和探索，能⼤幅提⾼測試效率。然⽽，許多⾴⾯藏在登入介⾯ ( 表單 ) 之\\n後，必須有正確的輸入才能繼續向後探索。因此為了解決以上問題，並增加網⾴測試的\\n覆蓋率，是本研究的⽬標。⾯對需要輸入值的表單時，要有適當的策略\\n我們先前提出結合網⾴爬蟲以及強化學習代理⼈的⽅法，名為  USAGI\\nUSAGI 透過代理⼈來填寫表單\\n去年結合應⽤⼤型語⾔模型（ LLM ）和提⽰微調（ Prompt Tuning ）的⽅法\\nFuzz( 建宏老師 )\\nREST API Fuzzing\\n主要著重在研究  REST API 的⿊箱模糊測試，以  OpenAPI 文件作為輸入，解析其中的  API\\n規格敘述，產⽣不同的 API 序列，並⽣成 API 請求所需要的參數值，希望達到更好的 status\\ncode coverage 以及 code coverage 。\\nTool: Restler\\nIntegrate LLM into Restler\\nGoogle Fuzzing(with 郭老師 )\\n研究如何透過 LLM 增強模糊測試的效能\\n微服務 ( 建宏老師  with 梁老師 )\\n112 年開始，還沒有很明確的內容\\nLLM 呼叫各類的 API 達成 RAG 的功效 ( ⽅法⽬前還在看論文看要改進哪個階段 )\\n針對微服務的效能測試相關 ( 細節還沒定下來 )\\n醫療影像辨識 ( 尤老師  with 振興醫院 )\\n2025/1/10 下午 4:20 實驗室簡介  - HackMD\\nhttps://hackmd.io/@fNmP5OVcSRmw0KivmULuHg/B1-cFT6gkl 4/10'), Document(metadata={'source': 'docs/SElab_Industry_Academia_Collaboration.pdf', 'page': 2}, page_content='使⽤⼼臟彩⾊都⼘勒影像於⽣物⼈⼯主動脈瓣膜異常偵測\\n彩⾊都⼘勒（ Color doppler ）是⼀種能有效評估⼼臟瓣膜功能的影像技術\\n⽬前尚無研究將  AI 應⽤於動脈瓣膜置換術後⽣物⼈⼯瓣膜異常的偵測\\n本研究採⽤數個模型與現有模型比較，證明應⽤之可⾏性\\n現況：\\n利⽤  Grad-Cam 視覺化判斷模型關注的特徵\\n使⽤演算法判斷影像的亂流區塊\\nDuplex 增加資料集的可⾏性\\n使⽤ SwinUNETR 模型對主動脈剝離  CT 影像辨別剝離型別 (Type A/B)\\n主動脈負責將⾎液輸送到全⾝維持⽣理機能\\n主動脈剝離意即動脈內層破裂，⾎流會跑到中層以及外層，將主動脈撕裂成假腔和真腔\\n假腔會壓迫到真腔，讓⾎液無法供應⾄全⾝，造成缺⾎的現象\\n先前使⽤ SwinUNETR 模型進⾏影像切割\\n現況：\\n判斷  Type A 病⼈的⼿術後恢復情況\\n以⼿術⽇期到出院⽇期計算，並⽤ 30 天為分界分類重症與輕症\\n歌曲⼈聲辨識 ( 建宏老師  with 尤老師 )\\n主要應⽤於旋律提取、 KTV 伴奏⼈聲去除、歌⼿辨識等\\n我們之前已經建構⼀個以頻譜圖為輸入的 CNN 模型，稱為  SCNN18\\n嘗試過：\\n複數神經網路\\nSelf-Supervised Learning\\n2025/1/10 下午 4:20 實驗室簡介  - HackMD\\nhttps://hackmd.io/@fNmP5OVcSRmw0KivmULuHg/B1-cFT6gkl 5/10'), Document(metadata={'source': 'docs/SElab_Industry_Academia_Collaboration.pdf', 'page': 3}, page_content='引入  Attention 機制\\n針對改進  SCNN18 ，因為正確率已經到達⼀個瓶頸，很難再提升\\n看尤老師有沒有想到新的⽅法\\n現況：\\nMIDI 格式之⼈⼯合成⾳樂判別\\n其他之前學⻑的研究可以看碩博⼠論文網 / 實驗室 NAS 上⾯\\n產學合作\\nSunbird 產學合作\\nCFS\\nSunBird 全端開發\\n效能測試  (Performance Testing)\\n資料庫 (PostgreSQL)\\nLinux\\nJmeter\\n寬橋產學合作\\n撰寫微服務的單元、整合、系統、效能與回歸測試\\n主要測試對象是寬橋的產品 Gravity\\nGoogle Fuzz\\n參考研究那的\\nAEB\\n113 年開始，⽬前還沒確定內容\\nSupermicro\\n看偉凱表演\\n2025/1/10 下午 4:20 實驗室簡介  - HackMD\\nhttps://hackmd.io/@fNmP5OVcSRmw0KivmULuHg/B1-cFT6gkl 6/10'), Document(metadata={'source': 'docs/SElab_Industry_Academia_Collaboration.pdf', 'page': 4}, page_content='113 年開始，⽬前還沒確定內容\\n2025/1/10 下午 4:20 實驗室簡介  - HackMD\\nhttps://hackmd.io/@fNmP5OVcSRmw0KivmULuHg/B1-cFT6gkl 7/10'), Document(metadata={'source': 'docs/SElab_Industry_Academia_Collaboration.pdf', 'page': 5}, page_content='FAQ\\n研究計畫與產學合作\\n內容參考上⾯\\n產學計畫\\nSunbird 全端開發⼀名  ( 碩⼀上每週 10 ⼩時，⼀下 ~ ⼆上每週 20 ⼩時 )\\nSunbird 效能測試兩名  ( 碩⼀下 ~ 碩⼆上結束，每週 10 ⼩時 )\\n助教\\n上學期：軟體⼯程、視窗程式設計 ( 、資料庫系統還不⼀定 )\\n下學期：軟體測試、 OOAD\\n以有修過課的⼈優先\\nGroup Meeting\\n8 ⽉底新⽣營後會開始加入⼀週⼀次的論文  Group Meeting\\n每週兩個⼈報告，主題都是實驗室有在做的研究⽅向\\n個⼈的研究  Meeting 會在⼀下接近學期末開始加入 ( 也是⼀週⼀次 )\\n如果想了解相關主題可以私底下詢問學⻑姊\\n碩論題⽬\\n主要接學⻑姊的研究，有⾃⼰想法也可以另外跟老師討論\\n⼤部分是來⾃計畫、部分是產學的延伸\\n多數產學不能當研究主題，只是去打⼯\\n計畫做⼀做就會⾃然有題⽬浮現出來惹\\n⼀定要寫作業嗎 ? ，作業不會寫怎麼辦 ?\\n我們實驗室要求學⽣有⼀定的程式基礎，如果無法完成作業可能不適合我們實驗室\\n若作業遇到問題，可以來信詢問學⻑姊，我們會適當的給予建議\\n實驗室安排\\n碩⼀上：修課為主，視需求要參與產學合作\\n碩⼀下：修課為主，學期末會加入研究會議與接學⻑姊的研究\\n碩⼆上：修完所有學分，主要時間在做研究\\n碩⼆下：完成研究與論文\\n畢業要求\\n完成⼀篇 TCSE 研討會論文 ( 中文 )\\n2025/1/10 下午 4:20 實驗室簡介  - HackMD\\nhttps://hackmd.io/@fNmP5OVcSRmw0KivmULuHg/B1-cFT6gkl 8/10'), Document(metadata={'source': 'docs/SElab_Industry_Academia_Collaboration.pdf', 'page': 6}, page_content='以下若新⽣有問再視情況決定要不要回答\\n平均幾年畢業\\n原則上 2 年，如有意外都是個⼈因素\\n⽬前實驗室有 1 位碩 3 ， 1 位碩 4\\n碩 3 學⻑是因為碩 2 上才找指導教授\\n碩 4 學姊是在電⼦系做論文，但因她學籍在資⼯系所以仍算我們實驗室的\\n未來就業\\n實驗室培養學⽣軟體⼯程的基礎，無論是要做什麼開發、測試等相關⼯作都問題不\\n⼤\\n歷屆學⻑有在台積電、聯發科、美超微、緯創、台達電、台達研究院、 HP 、威聯\\n通、中研院、 SunBird 等⼯作\\n什麼時候進實驗室\\n實驗室 8 ⽉中 ~ 底會舉辦為期三天的新⽣營\\n之後會開始⼀週⼀次的論文  Group Meeting\\n視前屆碩⼆離校情形，待整理好座位才會讓新⽣有座位\\n⼤約開學第三週 (9 ⽉底 10 ⽉初 ) 才會給個⼈座位\\n上班時間\\n責任制，除了實驗室公共事務 ( 如打掃 ) 之外，無強制打卡\\n實驗室提供每⼈⼀台電腦與⼀個螢幕使⽤\\n實驗室薪⽔\\n碩⼀除非有接助教 / 做產學否則沒有薪⽔\\n碩⼆開始主⼒放在做研究，實驗室會補貼 6000/ ⽉的薪⽔ ( 約 12 個⽉ )\\n如果碩⼀時有做產學，會⽤另外的⽅式計算\\n助教與⼯讀等不計入實驗室薪⽔中\\n實驗室雜務\\n實驗室有總務、財務、網管 *2 等職位，負責處理⼤部分的實驗室事務\\n實驗室氣氛\\n視每屆情況不同\\n現在這屆碩⼆的感情就很不錯，很歡樂 w\\n老師個性\\n偏佛系，會⽤講故事的⽅式講道理\\n具體可以跟老師⾯談感受⼀下，看這樣的風格是否可以接受\\n2025/1/10 下午 4:20 實驗室簡介  - HackMD\\nhttps://hackmd.io/@fNmP5OVcSRmw0KivmULuHg/B1-cFT6gkl 9/10'), Document(metadata={'source': 'docs/SElab_Industry_Academia_Collaboration.pdf', 'page': 7}, page_content='佛⼼建議\\n覺得研究⽅向  OK\\n對軟體⼯程有興趣，作業寫得出來\\n老闆的頻率有對到\\n以上都  OK 再來我們實驗室\\n2025/1/10 下午 4:20 實驗室簡介  - HackMD\\nhttps://hackmd.io/@fNmP5OVcSRmw0KivmULuHg/B1-cFT6gkl 10/10')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"docs/SElab_Industry_Academia_Collaboration.pdf\")\n",
    "docs = loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split doc and create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ask question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "實驗室有Sunbird全端開發、Sunbird效能測試計劃、助教等產業合作。新生會在8月中 ~ 底進實驗室，之後可以參與每周一次的論文Group Meeting。碩論題主要接受學費姐的研究，且需要有定義的程式基礎。\n",
      "\n",
      "在實驗室，學生必須完成作業，若遇到問題可以來信询问学长，我们会提供相应的建议。實驗室安排上，碩一期主要修課，視需求參與產業合作。\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"實驗室的產學合作有哪些?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
